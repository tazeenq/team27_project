{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    1000 non-null   int64 \n",
      " 1   Date              1000 non-null   object\n",
      " 2   Customer ID       1000 non-null   object\n",
      " 3   Gender            1000 non-null   object\n",
      " 4   Age               1000 non-null   int64 \n",
      " 5   Product Category  1000 non-null   object\n",
      " 6   Quantity          1000 non-null   int64 \n",
      " 7   Price per Unit    1000 non-null   int64 \n",
      " 8   Total Amount      1000 non-null   int64 \n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 70.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 998 entries, 0 to 997\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   transaction_id    998 non-null    int64         \n",
      " 1   date              998 non-null    datetime64[ns]\n",
      " 2   customer_id       998 non-null    object        \n",
      " 3   gender            998 non-null    object        \n",
      " 4   age               998 non-null    float64       \n",
      " 5   product_category  998 non-null    object        \n",
      " 6   quantity          998 non-null    float64       \n",
      " 7   price_per_unit    998 non-null    float64       \n",
      " 8   total_amount      998 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(3)\n",
      "memory usage: 70.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    transaction_id       date customer_id  gender       age product_category  \\\n",
       " 0               1 2023-11-24     CUST001    Male  0.347826           Beauty   \n",
       " 1               2 2023-02-27     CUST002  Female  0.173913         Clothing   \n",
       " 2               3 2023-01-13     CUST003    Male  0.695652      Electronics   \n",
       " 3               4 2023-05-21     CUST004    Male  0.413043         Clothing   \n",
       " 4               5 2023-05-06     CUST005    Male  0.260870           Beauty   \n",
       " \n",
       "    quantity  price_per_unit  total_amount  \n",
       " 0  0.666667        0.052632      0.063291  \n",
       " 1  0.333333        1.000000      0.493671  \n",
       " 2  0.000000        0.010526      0.002532  \n",
       " 3  0.000000        1.000000      0.240506  \n",
       " 4  0.333333        0.052632      0.037975  )"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Loading the dataset\n",
    "dataset_file_path = \"C:\\\\Users\\\\TazeenQ\\\\team27_project\\\\data\\\\raw\\\\retail_sales_dataset.csv\"\n",
    "retail_data = pd.read_csv(dataset_file_path)\n",
    "\n",
    "#Displaying the first couple of rows to check the data\n",
    "retail_data.head(), retail_data.info()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I hav\n",
    "\n",
    "#Renaming column names\n",
    "retail_data.rename(columns = lambda x: x.strip().replace(\" \", \"_\").lower(), inplace = True)\n",
    "\n",
    "#Standardizing data types\n",
    "#Converting date to datetime\n",
    "retail_data['date'] = pd.to_datetime(retail_data['date'], errors = 'coerce')\n",
    "\n",
    "#Handling missing values by replacing blanks with NaN and checking for missing values\n",
    "retail_data.replace(\"\", np.nan, inplace = True)\n",
    "missing_summary = retail_data.isnull().sum()\n",
    "\n",
    "#Dropping rows with date missing\n",
    "retail_data.dropna(subset = ['date'], inplace = True)\n",
    "\n",
    "#Filtering data, the dataset has values from 2023 and only 2 rows with data from 2024. I am removing those 2 rows.\n",
    "retail_data = retail_data[retail_data['date'].dt.year != 2024].reset_index(drop = True)\n",
    "\n",
    "#Summarizing dataset features\n",
    "summary_stats = retail_data.describe(include = 'all')\n",
    "\n",
    "#Choosing numerical columns to normalize\n",
    "numerical_cols = ['age', 'quantity', 'price_per_unit', 'total_amount']\n",
    "\n",
    "#Normalizng them\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(retail_data[numerical_cols])\n",
    "\n",
    "#Creating a new DataFrame for the normalized data\n",
    "normalized_dataset = retail_data.copy()\n",
    "normalized_dataset[numerical_cols] = pd.DataFrame(normalized_data, columns = numerical_cols)\n",
    "\n",
    "#Hot encoding my categorical variables\n",
    "categorical_columns = ['gender', 'product_category']\n",
    "encoded_date = pd.get_dummies(normalized_dataset, columns = categorical_columns, drop_first = False) #true for logistic regression (drop beauty category), false for KNN and random forests - multicollinearity\n",
    "\n",
    "#Saving the normalized dataset to a new file\n",
    "cleaned_dataset_file_path = \"C:\\\\Users\\\\TazeenQ\\\\team27_project\\\\data\\\\processed\\\\processed_retail_sales_dataset.csv\"\n",
    "normalized_dataset.to_csv(cleaned_dataset_file_path, index = False) \n",
    "\n",
    "normalized_dataset.info(), normalized_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Applying Statistical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 998 entries, 0 to 997\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        998 non-null    int64  \n",
      " 1   transaction_id    998 non-null    int64  \n",
      " 2   date              998 non-null    object \n",
      " 3   customer_id       998 non-null    object \n",
      " 4   gender            998 non-null    object \n",
      " 5   age               998 non-null    float64\n",
      " 6   product_category  998 non-null    object \n",
      " 7   quantity          998 non-null    float64\n",
      " 8   price_per_unit    998 non-null    float64\n",
      " 9   total_amount      998 non-null    float64\n",
      "dtypes: float64(4), int64(2), object(4)\n",
      "memory usage: 78.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4936708860759494,\n",
       "    total_amount  high_spender\n",
       " 0      0.063291             0\n",
       " 1      0.493671             0\n",
       " 2      0.002532             0\n",
       " 3      0.240506             0\n",
       " 4      0.037975             0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed dataset\n",
    "file_path = \"C:\\\\Users\\\\TazeenQ\\\\team27_project\\\\data\\\\processed\\\\processed_retail_sales_dataset.csv\"\n",
    "retail_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and summary info to understand the structure of the dataset\n",
    "retail_data.head(), retail_data.info()\n",
    "\n",
    "# Calculate the 80th percentile threshold for 'total_amount'\n",
    "high_spender_threshold = retail_data['total_amount'].quantile(0.8)\n",
    "\n",
    "# Add a new column 'high_spender' to classify customers based on the threshold\n",
    "retail_data['high_spender'] = (retail_data['total_amount'] > high_spender_threshold).astype(int)\n",
    "\n",
    "# Display the threshold and a sample of the updated dataset\n",
    "high_spender_threshold, retail_data[['total_amount', 'high_spender']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Spenders - for advertising. <br>\n",
    "Subset of original sample, with equal high and low spenders. Make sure when you're choosing from low spender its randomly chosen. Do it manually.<br>\n",
    "Should I show everything that hasn't worked? keep a test code file for everything that hasn't worked.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
